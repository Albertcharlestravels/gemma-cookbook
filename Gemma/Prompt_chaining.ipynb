{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2024 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718203564774,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfsDR_omdNea"
   },
   "source": [
    "# Gemma - Prompt Chaining and Iterative Generation\n",
    "This notebook demonstrates how to use prompt chaining and iterative generation with Gemma through a story writing example.\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/gemma-cookbook/blob/main/Gemma/Prompt_chaining.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaqZItBdeokU"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Select the Colab runtime\n",
    "To complete this tutorial, you'll need to have a Colab runtime with sufficient resources to run the Gemma model. In this case, you can use a T4 GPU:\n",
    "\n",
    "1. In the upper-right of the Colab window, select **‚ñæ (Additional connection options)**.\n",
    "2. Select **Change runtime type**.\n",
    "3. Under **Hardware accelerator**, select **T4 GPU**.\n",
    "\n",
    "### Gemma setup\n",
    "\n",
    "To complete this tutorial, you'll first need to complete the setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). The Gemma setup instructions show you how to do the following:\n",
    "\n",
    "* Get access to Gemma on kaggle.com.\n",
    "* Select a Colab runtime with sufficient resources to run\n",
    "  the Gemma 2B model.\n",
    "* Generate and configure a Kaggle username and an API key as Colab secrets.\n",
    "\n",
    "After you've completed the Gemma setup, move on to the next section, where you'll set environment variables for your Colab environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY2kGtsyYpHF"
   },
   "source": [
    "### Configure your credentials\n",
    "\n",
    "Add your your Kaggle credentials to the Colab Secrets manager to securely store it.\n",
    "\n",
    "1. Open your Google Colab notebook and click on the üîë Secrets tab in the left panel. <img src=\"https://storage.googleapis.com/generativeai-downloads/images/secrets.jpg\" alt=\"The Secrets tab is found on the left panel.\" width=50%>\n",
    "2. Create new secrets: `KAGGLE_USERNAME` and `KAGGLE_KEY`\n",
    "3. Copy/paste your username into `KAGGLE_USERNAME`\n",
    "3. Copy/paste your key into `KAGGLE_KEY`\n",
    "4. Toggle the buttons on the left to allow notebook access to the secrets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2503,
     "status": "ok",
     "timestamp": 1718203567276,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "A9sUQ4WrP-Yr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Note: `userdata.get` is a Colab API. If you're not using Colab, set the env\n",
    "# vars as appropriate for your system.\n",
    "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
    "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwjo5_Uucxkw"
   },
   "source": [
    "### Install dependencies\n",
    "Run the cell below to install all the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r_nXPEsF7UWQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203578807,
     "user_tz": -120,
     "elapsed": 11533,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U tensorflow keras keras-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOAEiJmnBE0D"
   },
   "source": [
    "## Prompt chaining\n",
    "\n",
    "Prompt chaining is a powerful technique for managing complex tasks that are difficult to accomplish in a single step.\n",
    "\n",
    "It entails breaking a large task into smaller, linked prompts, where each prompt's output feeds into the next. This step-by-step method steers the language model through the process. Key advantages include:\n",
    "\n",
    "\n",
    "\n",
    "*   Enhanced accuracy: Focused, smaller prompts produce better results from the language model.\n",
    "*   Easier debugging: Pinpointing and fixing issues within the chain is straightforward, allowing for precise improvements.\n",
    "* Handling complexity: Dividing intricate problems into manageable steps enables the language model to address more complex tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iterative Generation\n",
    "Iterative generation is the process of creating the desired output step by step. This method is particularly useful for writing stories that exceed the length limitations of a single generation window. The advantages of iterative generation include:\n",
    "\n",
    "* Extended outputs: It enables the production of longer and more detailed content, going beyond the constraints of a single generation window.\n",
    "* Enhanced flexibility: Adjustments and refinements can be made at each\n",
    "iteration, ensuring the story progresses as intended.\n",
    "* Human oversight: Feedback and guidance can be provided at each step, ensuring the story stays true to the creator's vision.\n",
    "\n",
    "\n",
    "By using **prompt chaining** and **iterative generation** together, you can create an interesting and well-structured story, adding to it piece by piece, while still having control over how it unfolds."
   ],
   "metadata": {
    "id": "MTDrbUbiyhHL"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3sX2mFH4GWk"
   },
   "source": [
    "### Gemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz47tAgSKMNH"
   },
   "source": [
    "**About Gemma**\n",
    "\n",
    "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.\n",
    "\n",
    "Here's the [official documentation](https://ai.google.dev/gemma/docs/formatting) regarding promping instruction-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4241,
     "status": "ok",
     "timestamp": 1718203583045,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "B3WckZv2hef3"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33071,
     "status": "ok",
     "timestamp": 1718203616113,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "8dfseDZChhjl",
    "outputId": "2a895c1e-6761-4486-8b95-e426d0dc3ce2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'task.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n"
     ]
    }
   ],
   "source": [
    "# Let's load Gemma using Keras\n",
    "gemma_model_id = \"gemma_1.1_instruct_2b_en\"\n",
    "gemma = keras_nlp.models.GemmaCausalLM.from_preset(gemma_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Story writing baseline: persona, premise, outline"
   ],
   "metadata": {
    "id": "fEhPz8PZuRcm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the first step, we'll create a persona, which the LLM should take to perform the task. In this example, we want it to act like a children's author, who wants to write a new funny and educating story."
   ],
   "metadata": {
    "id": "u97asfO3uU-x"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "persona = \"\"\"You are a children's author with a penchant for humorous, yet educating stories.\n",
    "Your ultimate goal is to write a new story to be published in a children magazine.\"\"\""
   ],
   "metadata": {
    "id": "i4Qg0dYqu5UL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203616113,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The upcoming subtask for the LLM is to develop a premise for the story. To achieve this, we require a prompt. We'll use the persona description to generate the premise prompt. In this example, we want the model to create a story about bunnies."
   ],
   "metadata": {
    "id": "ZhniNs61u-Ku"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "premise_prompt = f\"\"\"<start_of_turn>user\n",
    "{persona}\n",
    "\n",
    "Write a single-sentence premise for a children's story featuring bunnies.<end_of_turn>\n",
    "<start_of_turn>model\\n\"\"\""
   ],
   "metadata": {
    "id": "XHXTQdNvu7L0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203616113,
     "user_tz": -120,
     "elapsed": 1,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "premise_response = gemma.generate(premise_prompt, max_length=512)\n",
    "premise = premise_response[len(premise_prompt) :]\n",
    "display(Markdown(premise))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "DyOvDcBkv5s1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203677884,
     "user_tz": -120,
     "elapsed": 61772,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    },
    "outputId": "e6a5fcd8-8cdb-4179-ec15-1b255ef6d181"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "In the bustling meadow of Whispering Woods, a clumsy bunny named Pip learns that even the smallest of creatures can achieve extraordinary things when they work together."
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll use the generated premise to create a prompt for the next step, which will produce the story outline.\n",
    "\n"
   ],
   "metadata": {
    "id": "IpJ55LJAvblz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "outline_prompt = f\"\"\"<start_of_turn>user\n",
    "{persona}\n",
    "\n",
    "You have a gripping premise in mind:\n",
    "\n",
    "{{premise}}\n",
    "\n",
    "Create an outline for your story's plot consisting of 5 key points.<end_of_turn>\n",
    "<start_of_turn>model\\n\"\"\""
   ],
   "metadata": {
    "id": "c4FHQw0avkQ0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203677885,
     "user_tz": -120,
     "elapsed": 3,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_outline_prompt = outline_prompt.format(premise=premise)\n",
    "outline_response = gemma.generate(full_outline_prompt, max_length=512)\n",
    "outline = outline_response[len(full_outline_prompt) :]\n",
    "display(Markdown(outline))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "PkT-L8i-v9xJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203687627,
     "user_tz": -120,
     "elapsed": 9744,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    },
    "outputId": "2d650f07-c1a5-460a-8e08-b3afd03f8ace"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Plot Outline:\n\n**1. The Clumsy Bunny:**\n- Pip, a timid bunny, struggles with his clumsy nature.\n- He dreams of doing something extraordinary but lacks the confidence to try.\n\n**2. The Whisper of Teamwork:**\n- Pip encounters a timid squirrel who inspires him to believe in his abilities.\n- Together, they discover the magic of working as a team.\n\n**3. The Power of Small Acts:**\n- Pip and the squirrel embark on small, seemingly insignificant tasks around the meadow.\n- These tasks gradually build confidence and a sense of accomplishment.\n\n**4. Overcoming Fear:**\n- Pip faces his biggest fear, which holds him back from achieving his dreams.\n- Through the support of his newfound friends, he learns to overcome his fear and embrace his potential.\n\n**5. The Celebration of Togetherness:**\n- Pip and the squirrel celebrate their achievements as a team.\n- They realize that even the smallest of creatures can achieve extraordinary things when they work together."
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have the plan, we'd like Gemma to begin writing the story. In the prompt, include all the necessary information we've gathered so far: the persona, premise, and outline.\n"
   ],
   "metadata": {
    "id": "9iYpDaIzv_hC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1718203701280,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "lWWLFF24pFOe"
   },
   "outputs": [],
   "source": [
    "starting_prompt = f\"\"\"<start_of_turn>user\n",
    "{persona}\n",
    "\n",
    "You have a gripping premise in mind:\n",
    "\n",
    "{{premise}}\n",
    "\n",
    "Your imagination has crafted a narrative outline:\n",
    "\n",
    "{{outline}}\n",
    "\n",
    "First, silently review the outline and the premise. Consider how to start the\n",
    "story.\n",
    "\n",
    "Your task is to write a part of the story that covers only the first point of the outline.\n",
    "You are not expected to finish the whole story now.\n",
    "Do not write about the next points, only the first one plot point!!!\n",
    "\n",
    "Try to write 10 sentences.\n",
    "Remember, DO NOT WRITE A WHOLE STORY RIGHT NOW.<end_of_turn>\n",
    "<start_of_turn>model\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "full_starting_prompt = starting_prompt.format(premise=premise, outline=outline)\n",
    "starting_response = gemma.generate(full_starting_prompt, max_length=1000)\n",
    "draft = starting_response[len(full_starting_prompt) :]\n",
    "display(Markdown(draft))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "Fdu7kVqVwRXQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203766612,
     "user_tz": -120,
     "elapsed": 63826,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    },
    "outputId": "ad8b3cfa-8146-4e3f-8bdf-3bb09cd38d7a"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Pip, a bunny with fur as white as freshly fallen snow, sat nestled beneath a towering oak, his eyes fixed on the path ahead. His heart thumped a frantic rhythm against his ribs, a counterpoint to the gentle rustling of leaves in the wind. He dreamt of soaring through the sky, of his name echoing through the vast meadow, but fear held him captive.\n\nThe memory of his clumsy attempts to hop and skip always surfaced, tripping him over pebbles and sending him sprawling in a heap. He longed to be like the other bunnies, agile and graceful, but his clumsy nature held him captive."
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you're pleased with the start of your story, you can continue it by further prompting the model with the text written so far. You can also add guidelines to help the model write appropriately and avoid concluding the story too quickly."
   ],
   "metadata": {
    "id": "MHnP5quYwYLu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1718203886401,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "ZdFyNiFQ4UZW"
   },
   "outputs": [],
   "source": [
    "guidelines = \"\"\"Writing Guidelines\n",
    "\n",
    "Remember, your main goal is to write as much as you can. If you get through\n",
    "the story too fast, that is bad. Expand, never summarize. Don't repeat previous\n",
    "parts of the story, only expand.\"\"\"\n",
    "\n",
    "\n",
    "continuation_prompt = f\"\"\"<start_of_turn>user\n",
    "{persona}\n",
    "\n",
    "You have a following premise in mind:\n",
    "\n",
    "{{premise}}\n",
    "\n",
    "The outline of the story looks like this:\n",
    "\n",
    "{{outline}}\n",
    "\n",
    "\n",
    "Here's what you've written so far:\n",
    "\n",
    "{{story_text}}\n",
    "\n",
    "\n",
    "=====\n",
    "First, silently review the premise, the outline and the story you've written so far.\n",
    "\n",
    "Write the continuation - the next 5 sentences that cover the next outline point. Stick to the outline.\n",
    "\n",
    "However, once the story is COMPLETELY finished, write IAMDONE.\n",
    "\n",
    "{guidelines}<end_of_turn>\n",
    "<start_of_turn>model\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 13220,
     "status": "ok",
     "timestamp": 1718203900065,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     },
     "user_tz": -120
    },
    "id": "M7VM7COm22Hz",
    "outputId": "e38d5b75-00cf-49a4-a569-cd8d4c081640"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Pip sighed, his whiskers twitching in frustration. He hopped closer to the edge of the meadow, his eyes scanning the vast expanse. A sense of longing gnawed at him, a yearning to do something extraordinary, something that would make him truly shine.\n\nSuddenly, a flicker of inspiration struck him. He remembered the squirrel he had seen earlier, timid and hesitant, but radiating an aura of quiet confidence. A smile crept across Pip's face. He knew what he had to do.\n\nWith newfound determination, Pip hopped towards the squirrel, his tiny paws extending a gentle touch towards his friend. \"Let's do this,\" he whispered, his voice barely above a whisper.\n\nTogether, Pip and the squirrel began their small but mighty tasks. Pip carefully placed pebbles to create a path for the squirrel, while the squirrel, with her nimble leaps, helped him reach higher branches.\n\nAs they worked side by side, the meadow came alive with their collaborative efforts. The sun shone brighter, the wind rustled the leaves, and the air buzzed with a sense of purpose.\n\nPip and the squirrel, their bond stronger than ever, realized that even the smallest of creatures could achieve extraordinary things when they worked together. And so, their tale of teamwork was whispered throughout the meadow, inspiring other timid creatures to believe in their own potential."
     },
     "metadata": {}
    }
   ],
   "source": [
    "full_continuation_prompt = continuation_prompt.format(\n",
    "    premise=premise, outline=outline, story_text=draft\n",
    ")\n",
    "continuation_response = gemma.generate(full_continuation_prompt, max_length=1000)\n",
    "continuation = continuation_response[len(full_continuation_prompt) :]\n",
    "display(Markdown(continuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add the continuation to the initial draft, keep building the story iteratively, until 'IAMDONE' is seen"
   ],
   "metadata": {
    "id": "yX8G_SlOxIB6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "az0Zk9MA1XqU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718203987734,
     "user_tz": -120,
     "elapsed": 77332,
     "user": {
      "displayName": "Adam Czy≈ºewski",
      "userId": "01400811009110984524"
     }
    },
    "outputId": "0ec0c835-0387-43cf-8556-145c2b06cb19"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Pip, a bunny with fur as white as freshly fallen snow, sat nestled beneath a towering oak, his eyes fixed on the path ahead. His heart thumped a frantic rhythm against his ribs, a counterpoint to the gentle rustling of leaves in the wind. He dreamt of soaring through the sky, of his name echoing through the vast meadow, but fear held him captive.\n\nThe memory of his clumsy attempts to hop and skip always surfaced, tripping him over pebbles and sending him sprawling in a heap. He longed to be like the other bunnies, agile and graceful, but his clumsy nature held him captive.\n\nPip sighed, his whiskers twitching in frustration. He hopped closer to the edge of the meadow, his eyes scanning the vast expanse. A sense of longing gnawed at him, a yearning to do something extraordinary, something that would make him truly shine.\n\nSuddenly, a flicker of inspiration struck him. He remembered the squirrel he had seen earlier, timid and hesitant, but radiating an aura of quiet confidence. A smile crept across Pip's face. He knew what he had to do.\n\nWith newfound determination, Pip hopped towards the squirrel, his tiny paws extending a gentle touch towards his friend. \"Let's do this,\" he whispered, his voice barely above a whisper.\n\nTogether, Pip and the squirrel began their small but mighty tasks. Pip carefully placed pebbles to create a path for the squirrel, while the squirrel, with her nimble leaps, helped him reach higher branches.\n\nAs they worked side by side, the meadow came alive with their collaborative efforts. The sun shone brighter, the wind rustled the leaves, and the air buzzed with a sense of purpose.\n\nPip and the squirrel, their bond stronger than ever, realized that even the smallest of creatures could achieve extraordinary things when they worked together. And so, their tale of teamwork was whispered throughout the meadow, inspiring other timid creatures to believe in their own potential.\n\nPip and the squirrel continued their small but mighty tasks, their laughter echoing through the meadow. The sun beat down on their fur, but their spirits remained warm, their determination as strong as the oak trees that stood tall around them.\n\nAs they worked, Pip noticed that the squirrels were struggling to reach the highest branches. With a smile, he hopped down and gently nudged them with his tiny nose. The squirrels looked up, surprised by the bunny's kindness.\n\n\"Thank you,\" said one squirrel, her voice soft but grateful. \"We couldn't have reached those leaves without you.\"\n\nPip nodded, his heart filled with joy. He had helped his friends, and he had discovered a new sense of purpose.\n\nTogether, Pip and the squirrel continued their journey, their bond growing stronger with each passing day. They learned that even the smallest of creatures could achieve extraordinary things when they worked together, and that the most important thing was to believe in oneself and the power of friendship.\n\nPip and the squirrel continued their journey, their bond growing stronger with each passing day. They learned that even the smallest of creatures could achieve extraordinary things when they worked together, and that the most important thing was to believe in oneself and the power of friendship.\n\nOne day, they stumbled upon a group of butterflies struggling to navigate the maze-like meadow. Pip and the squirrel, with their combined strength and determination, helped them find their way out.\n\nAs they flew higher and higher, the meadow spread out beneath them like a breathtaking tapestry. Pip and the squirrel felt a sense of pride and accomplishment wash over them.\n\nThey realized that their teamwork had not only helped the butterflies but had also strengthened their own bond. They had learned that even the smallest of creatures could make a big difference when they worked together, and that the most important thing was to believe in themselves and the power of friendship.\n\nPip and the squirrel continued their adventures, their laughter echoing through the meadow. They knew that they had achieved something truly special, and they were grateful for the opportunity to have worked together.\n\nPip and the squirrel continued their adventures, their laughter echoing through the meadow. They knew that they had achieved something truly special, and they were grateful for the opportunity to have worked together.\n\nTheir journey led them to a hidden grove of wildflowers where they discovered a magical elixir that granted them the ability to grow taller and stronger. With newfound confidence, they soared high above the meadow, their laughter filling the air.\n\nAs they flew, they noticed a group of birds struggling to build their nests. Pip and the squirrel, with their combined strength and wisdom, helped them find the best materials and build the most sturdy nests.\n\nThe birds were amazed by their kindness and offered their thanks. Pip and the squirrel felt a sense of purpose and fulfillment knowing that they had made a difference in the lives of others.\n\nThey continued their adventures, exploring new and exciting places together. They learned that even the smallest of creatures could achieve extraordinary things when they worked together, and that the most important thing was to believe in themselves and the power of friendship.\n\n."
     },
     "metadata": {}
    }
   ],
   "source": [
    "draft = draft + \"\\n\\n\" + continuation\n",
    "\n",
    "while \"IAMDONE\" not in continuation:\n",
    "    full_continuation_prompt = continuation_prompt.format(\n",
    "        premise=premise, outline=outline, story_text=draft\n",
    "    )\n",
    "    continuation_response = gemma.generate(full_continuation_prompt, max_length=5000)\n",
    "    continuation = continuation_response[len(full_continuation_prompt) :]\n",
    "    draft = draft + \"\\n\\n\" + continuation\n",
    "\n",
    "# Remove 'IAMDONE' and print the final story\n",
    "final = draft.replace(\"IAMDONE\", \"\").strip()\n",
    "display(Markdown(final))"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "kOjbPfsY7wSw"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1pnjCjEr5dP2aLh5IgNo4DfCPTOZIsjfF",
     "timestamp": 1718202083859
    },
    {
     "file_id": "1R9oMUR2z9i6F_0OhJ2w_ArvkK1aFg6eh",
     "timestamp": 1718194808574
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
